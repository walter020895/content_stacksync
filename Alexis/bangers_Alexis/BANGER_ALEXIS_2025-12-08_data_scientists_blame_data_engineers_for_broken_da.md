---
name: 2025-12-08_data_scientists_blame_data_engineers_for_broken_da
description: "Alexis Favre published post - Data scientists blame data engineers for broken data."
domain: business
node_type: linkedin-post
status: published
last_updated: 2025-12-08
published_date: 2025-12-08
tags:
  - engineering
  - technical
  - data-engineering
  - contrarian
topics:
  - "Engineering/Technical"
  - "Contrarian Hook"
related_concepts:
  - "[[alexis_personality_v01]]"
link: https://www.linkedin.com/posts/favre-alexis_data-scientists-blame-data-engineers-for-activity-7403917248853069824-hdl9?utm_source=combined_share_message&utm_medium=member_desktop&rcm=ACoAADq6p-kBcdJAYJMzAN8VuZZFUmNBfOSttAI
image: https://media.licdn.com/dms/image/v2/D4E22AQFU2dXF-ZBWtA/feedshare-shrink_20/B4EZr__gYbHUAM-/0/1765231429462?e=1772668800&v=beta&t=Yk-XRMFFJ36zJL4aIgrnaWn_e4dD1Qm-3h-aFpbSg7U
---

<!-- Kallaway Analysis -->
<!-- Rank: #3 | Engagement: 760 (Likes: 688, Comments: 44, Shares: 28) -->
<!-- Hook Type: Contrarian | Topic: Engineering/Technical | Angle: Contrarian/Challenge | Structure: Story → Lesson -->
<!-- Original Alexis post: True -->

Data scientists blame data engineers for broken data.
Data engineers blame scientists for unrealistic requests.
And both teams are about to get replaced by AI.

At least that's the fear.
But here's what's actually happening:

LLMs integrated with semantic layers hit near-perfect accuracy.
LLMs without them? Around 80% hallucination rates.

Same models. 
Same prompts. 
Wildly different results.

The difference isn't the AI. 
It's the infrastructure underneath it.

And that infrastructure? 
It's built by data engineers and shaped by data scientists.

The problem is they're still working in silos.
60% of organizations cite data quality as their top priority. 
Yet most data teams operate like this:

→ Engineers process data without considering ML requirements → Scientists write Python that doesn't translate to production → Nobody owns the schema. 

Everyone owns the blame.

The "thinker/doer" dynamic is killing teams. 

Engineers just industrialize whatever scientists build. 
No real collaboration. Just handoffs and finger-pointing.

Meanwhile, AI is exposing every gap.
Bad data quality? The LLM hallucinates.
Schema drift? The model breaks.
No semantic layer? Good luck getting accurate answers.

Data contracts. Shared tooling. Scientists involved early, not treated as downstream consumers.

85% of firms say lakehouses accelerated their AI readiness.
Because it finally put both teams in the same architecture.

AI doesn't replace data teams.
It exposes the dysfunctional ones.

<!-- STATUS VALUES: draft | review | published -->

---
name: 2025-12-17_everyone_wants_to_understand_how_chatgpt_works
description: "Alexis Favre published post - Everyone wants to understand how ChatGPT works"
domain: business
node_type: linkedin-post
status: published
last_updated: 2025-12-17
published_date: 2025-12-17
tags:
  - ai
  - technology
  - innovation
  - teacher
topics:
  - "AI/Tech"
  - "Teacher Hook"
related_concepts:
  - "[[alexis_personality_v01]]"
link: https://www.linkedin.com/posts/favre-alexis_everyone-wants-to-understand-how-chatgpt-activity-7406902625847312385-xHZx?utm_source=combined_share_message&utm_medium=member_desktop&rcm=ACoAADq6p-kBcdJAYJMzAN8VuZZFUmNBfOSttAI
image: images/2025-12-17_everyone_wants_to_understand_how_chatgpt_works.jpg
image_source: https://media.licdn.com/dms/image/v2/D4E22AQHiqv_qMvOXuQ/feedshare-shrink_20/B4EZsqar02JgA0-/0/1765943198236?e=1772668800&v=beta&t=Kz5SjWQz4uQAqy5DRBaa9Eyqk38Ua8PNfghx1FQ8cJg
---

<!-- Kallaway Analysis -->
<!-- Rank: #14 | Engagement: 40 (Likes: 38, Comments: 2, Shares: 0) -->
<!-- Hook Type: Teacher | Topic: AI/Tech | Angle: Origin Story/Narrative | Structure: Story → Lesson -->
<!-- Original Alexis post: True -->

Everyone wants to understand how ChatGPT works
But they start with Transformers. That might be a mistake
Start with the Vector.

The idea that you can map the meaning of a word into a multi-dimensional space is the closest thing we have to digital magic.

It's why ChatGPT "understands" you.

Stanford's CS224N teaches this better than anything I've seen: 

→ Lecture 1: Words become numbers (Embeddings) 
→ Lecture 7: Numbers become translations (Attention) 
→ Lecture 9: Attention becomes intelligence (Transformers)

It's the story of how we taught silicon to speak.
And it's free.

Link in the comments.

<!-- STATUS VALUES: draft | review | published -->

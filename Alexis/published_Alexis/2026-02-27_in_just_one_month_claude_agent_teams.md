---
name: ai_autonomy_vs_discipline
description: "Claude shipped agent teams. Perplexity shipped a 19-model autonomous computer. Cursor shipped self-iterating agents. Alexis's team shipped rules for not trusting any of it."
domain: business
node_type: linkedin-post
status: published
last_updated: 2026-02-27
published_date: 2026-02-27
tags:
  - ai-coding-tools
  - engineering-discipline
  - claude-code
  - perplexity
  - cursor
  - ai-autonomy
topics:
  - AI-assisted-development
  - engineering-culture
  - technical-leadership
related_concepts:
  - "[[ai-coding-discipline]]"
  - "[[human-in-loop]]"
link: https://www.linkedin.com/posts/favre-alexis_in-just-one-month-claude-agent-teams-perplexity-activity-7433254305400442880-RZTd
image: images/2026-02-27_in_just_one_month_claude_agent_teams.png
---

# ALEXIS — In Just One Month: Claude Agent Teams. Perplexity Computer. Cursor Agents. We Shipped Rules.
## Angle: Three AI launches in one month prove the market is pushing autonomy. Alexis pushes engineering discipline. His actual operating principles for the team — verbatim.

---

## IDEA LEGOS
| Lego | Choice |
|------|--------|
| User's Insight | Mode 1 (persona insight): Alexis's actual operating principles for his engineering team on how to use AI coding tools. Preserved verbatim. |
| Topic | Three companies shipped more AI autonomy in February 2026: Claude agent teams, Perplexity's 19-model autonomous computer, Cursor's self-iterating agents. The winning response isn't more autonomy — it's tighter discipline. |
| Angle | Alexis's CTO lens: he uses these tools daily and wrote operating rules for his team. The rules are the content. |
| Hook Type | Contrarian (industry going one way, Alexis going the other — with specific proof of which way) |
| Story Structure | News barrage → Contrarian turn → Operating principles (the real content) → Verdict |
| Psych Triggers | Tribal Identity (engineers who think before prompting) + Pattern Recognition (discipline > tools) |
| Visual Format | Image |
| Key Visuals | Document-style card with the operating principles as a "team memo" or split showing what they shipped vs what we shipped |

**Reader Value:** The ICP (CTO, VP Eng) walks away with a specific set of operating principles they can adapt for their own engineering team's AI tool usage. Directly actionable — they can copy these rules into their team docs today.

---

### HOOK A
Claude shipped agent teams. Perplexity shipped a 19-model autonomous computer. Cursor shipped agents that debug and iterate without you.

Our engineering principles go the other direction.

### HOOK B (Recommended)
Claude shipped agent teams. Perplexity shipped a 19-model autonomous computer. Cursor shipped agents that debug and iterate without you.

We shipped a list of rules for not trusting any of it.

### HOOK C
Three AI launches this month. Claude runs multi-agent teams. Perplexity runs 19 models as one autonomous system. Cursor runs agents that iterate alone.

We're shipping rules.

---

### VISUAL HOOKS

**Option A (Recommended):** Classified (Document) — SQUARE 1:1 — [TYPE][SVG]
"ENGINEERING OPERATING PRINCIPLES — AI TOOLS" header. Clean document layout with the key rules as numbered items. Stacksync logo bottom-right. Feels like an internal memo leaked.
Image-hook loop: Image reads like an internal team document. Hook says "we shipped rules." Second look: the reader is reading Alexis's actual team rules.

**Option B:** Split (Typographic) — SQUARE 1:1 — [TYPE][LOGO]
Left panel: "What they shipped" → Claude / Perplexity / Cursor logos with feature labels (agent teams / 19-model computer / self-iterating agents).
Right panel: "What we shipped" → "You are responsible for every line you push."
Image-hook loop: Image shows the contrast. Hook frames the philosophy. Second look: the specificity of the right panel stings.

**Option C:** Headline (Typographic) — PORTRAIT 4:5 — [TYPE]
Giant text: "KNOW EVERY LINE BY HEART." Smaller subtext: "Operating principle for AI-assisted engineering." Stacksync logo.
Image-hook loop: Image is a command. Hook provides context. Second look: feels like a poster in the engineering office.

---

### FULL POST (as published)

---

In just one month: Claude agent teams. Perplexity Computer. Cursor agents.

We shipped a list of rules for not trusting any of it.

Use AI to put characters on the keyboard for you. But you should have already had every single character in mind before it touches the screen.

Never let the AI think for you. You own the design and correctness of every line of code. The AI writes it down. You decide what gets written.

You choose every variable name. Every function name. You know by heart every single line of code you push. I'm serious about this.

Use AI to speed up finding root causes. Feed it Sentry context, stack traces, whatever helps.

But think through it yourself at the same time. No hotfixes without understanding the root cause first.

Speed matters. Fast iteration, fast time-to-fix. But fast and wrong is still wrong.

These tools are powerful when the operator is precise. When the operator is lazy, they produce the same output any cheap developer would.

You wouldn't hand a junior a vague ticket and expect quality. Same applies here.

---

## NOTES
- **Voice**: Alexis's CTO-as-leader voice. This is him talking TO his team, shared publicly. The "I'm serious about this" is preserved from his actual text — raw, direct, not polished. "Any cheap developer" is Alexis's contempt for mediocrity surfacing naturally. Teaching mode throughout — he's giving rules, not observations.
- **Idea Legos**: News barrage + Contrarian turn → Operating principles → Verdict
- **Reader value**: A CTO or VP Eng can take these principles and adapt them for their own team's AI usage. Specific, copy-pasteable, immediately actionable. Value exists independent of Stacksync.
- **Narrative arc**: (1) Three specific AI launches (hook — news barrage with escalating autonomy) → (2) Contrarian turn: we shipped rules → (3) The principles (the real content — 6 rules, each covering a different dimension) → (4) Verdict: powerful when precise, garbage when lazy → (5) Close: the junior analogy as callback
- **Storytelling techniques used**:
  - News barrage hook: three companies, three features, escalating autonomy (coordination → full computer → developer replacement). "Shipped" anaphora builds momentum; the 4th "shipped" turns it.
  - Contrast: industry direction vs Alexis's direction (macro tension throughout)
  - Escalation: each principle gets more demanding (characters → design → variable names → know by heart → root causes → speed)
  - Imperative voice: "You choose." "You own." "You know." — commands, not suggestions
  - Scene-placing: "Feed it Sentry context, stack traces" — specific tools, specific workflow
  - Fragment closer: "Same applies here." — drops the mic after the junior analogy
- **Psychological triggers**: Tribal Identity (engineers who think before prompting) + Pattern Recognition (discipline > autonomy)
- **Ego bait**: Engineers who already use AI tools with discipline feel validated. CTOs who worry about AI quality in their codebase get a framework. Claude/Perplexity/Cursor users all see their tools mentioned — no company attacked. The tools are praised as powerful; the operators are challenged.
- **Hook analysis (Kallaway)**: Three-part news setup + contrarian turn. Single subject: AI autonomy vs engineering discipline. Single question: "What rules?" Context Lean: "In just one month: Claude agent teams. Perplexity Computer. Cursor agents." (reader nods — these are real, recent launches they saw this week). Scroll Stop: "We shipped a list of rules for not trusting any of it." (the contrast + contempt). Snap Back: in body (the actual principles).
- **AI slop check**: Clean. No em dashes. No flip formulas. No "Here's the thing." No colon staging. "I'm serious about this" is preserved verbatim from Alexis — raw voice, not a template. "Same applies here" is a natural closer, not #20 ("It all comes down to this"). "Any cheap developer" is Alexis's actual language from his operating doc.
- **Formatting check**: Phone scroll test PASS. Max 2 sentences per paragraph. The principles section uses line-break rhythm — each principle is 1-2 sentences, separated by air. Single-sentence air lines: 4+. No text walls.
- **Redundancy sweep**: PASS. Each principle covers a different dimension: (1) keyboard discipline, (2) design ownership, (3) naming ownership, (4) root cause discipline, (5) speed balance, (6) operator quality verdict. No overlap.
- **Question Chain (sentence-by-sentence):**
  1. "In just one month: Claude agent teams. Perplexity Computer. Cursor agents." → Q: So what are you doing about it?
  2. "We shipped a list of rules for not trusting any of it." → A: The opposite. Q: What rules?
  3. "Use AI to put characters on the keyboard for you." → A: Use it. Q: But how?
  4. "But you should have already had every single character in mind before it touches the screen." → A: With total pre-design. Q: What does that look like in practice?
  5. "Never let the AI think for you." → A: Hard rule. Q: What are you responsible for?
  6. "You own the design and correctness of every line of code." → A: Everything. Q: What does the AI do then?
  7. "The AI writes it down. You decide what gets written." → A: It types, you think. Q: How specific does the control go?
  8. "You choose every variable name. Every function name." → A: Down to the naming. Q: Is that actually enforced?
  9. "You know by heart every single line of code you push." → A: Yes. Q: Really?
  10. "I'm serious about this." → A: Dead serious. Q: What about debugging?
  11. "Use AI to speed up finding root causes." → A: Use it there too. Q: How?
  12. "Feed it Sentry context, stack traces, whatever helps." → A: Specifics. Q: Any limits?
  13. "But think through it yourself at the same time." → A: Always in parallel. Q: What about quick fixes?
  14. "No hotfixes without understanding the root cause first." → A: No shortcuts. Q: But what about speed?
  15. "Speed matters. Fast iteration, fast time-to-fix." → A: Speed is real. Q: So what's the balance?
  16. "But fast and wrong is still wrong." → A: Quality wins. Q: So what determines the output?
  17. "These tools are powerful when the operator is precise." → A: The operator. Q: And when they're not?
  18. "When the operator is lazy, they produce the same output any cheap developer would." → A: Garbage. Q: What's the analogy?
  19. "You wouldn't hand a junior a vague ticket and expect quality." → A: The frame. Q: And AI?
  20. "Same applies here." → Closer. Answers the question. Opens nothing.
  **Chain status: 20 links, zero breaks.**
- **Overlap with Feb 16 post (Claude Code vs Codex)**: Different angle. Feb 16 = tool comparison ending with "junior" metaphor as conclusion. This post = operating discipline with specific news context and Alexis's verbatim principles. Feb 16 asked "which tool?" This post asks "how do you use ANY tool?" No shared sentences. No shared hook type. Different structure. The "junior" metaphor appears in both but serves different roles — conclusion vs. analogy-closer. 11+ days apart.
- **Stacksync mention**: None explicit. The principles are the content. Stacksync is implied through "we" and the Sentry/stack traces reference (shows a real engineering team).
- **Word count**: ~160
- **Audit score**: 8.95 GO
- **Factual sources**:
  - Claude agent teams (Opus 4.6): released Feb 5, 2026 (Anthropic)
  - Claude Sonnet 4.6: released Feb 17, 2026 (CNBC)
  - Perplexity Computer with 19 AI models: launched Feb 25, 2026 (TechCrunch, Semafor)
  - Cursor agent update (background agents, $29.3B valuation): Feb 24, 2026 (The Verge)
  - Alexis's operating principles: verbatim from internal team document (Mode 1 — persona's own content)
